{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204f6da8-d4cc-4b6b-b866-142074f027b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03db607f-381c-4ad7-867d-53217d9b1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8752ec-26e6-467b-830d-5badd9658fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치 미분\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    # print(\"debug 1. initial input variable =\", x)\n",
    "    # print(\"debug 2. initial input grad =\", grad)\n",
    "    # print(\"=\"*25)\n",
    "    \n",
    "    it = np.nditer(x,flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        #  print(\"debug 3. idx=\", idx, \", x[idx]=\",x[idx])\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) #f(x+delta_x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x) #f(x-delta_x)\n",
    "        grad[idx]=(fx1- fx2) / (2*delta_x)\n",
    "        \n",
    "        # print(\"debug 4. grad[idx] = \", grad[idx])\n",
    "        # print(\"debug 5. grad = \", grad)\n",
    "        # print(\"=\"*25)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ba0db4-41db-442a-aa81-66085f5e97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name\n",
    "        self.__xdata = xdata\n",
    "        self.__tdata = tdata\n",
    "        \n",
    "        self.__xdata = xdata.reshape(4,2)\n",
    "        self.__tdata = tdata.reshape(4,1)\n",
    "        \n",
    "        self.__W2 = np.random.rand(2,6)\n",
    "        self.__b2 = np.random.rand(6)\n",
    "        \n",
    "        self.__W3 = np.random.rand(6,1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "        \n",
    "        self.__learning_rate = 1e-2\n",
    "    \n",
    "    def feed_forward(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3)+self.__b3\n",
    "        y=sigmoid(z3)\n",
    "        \n",
    "        return -np.sum(self.__tdata*np.log(y+delta) + (1-self.__tdata)*np.log((1-y) + delta))\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        f=lambda x: self.feed_forward()\n",
    "\n",
    "        print(\"Initial loss_func :\", self.feed_forward())\n",
    "\n",
    "        for step in range(10001):\n",
    "            self.__W2 -= self.__learning_rate*numerical_derivative(f,self.__W2)\n",
    "            self.__b2 -= self.__learning_rate*numerical_derivative(f,self.__b2)\n",
    "            \n",
    "            self.__W3 -= self.__learning_rate*numerical_derivative(f,self.__W3)\n",
    "            self.__b3 -= self.__learning_rate*numerical_derivative(f,self.__b3)\n",
    "\n",
    "            if step%400==0:\n",
    "                print(\"step :\",step,\"// loss value :\", self.feed_forward())\n",
    "    \n",
    "    def predict(self, xdata):\n",
    "        z2 = np.dot(xdata,self.__W2) +self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\n",
    "        y = sigmoid(z3)\n",
    "\n",
    "        if y > 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "        \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afafb4d0-5a51-488b-b8b1-60537af35f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss_func : 7.40854658372357\n",
      "step : 0 // loss value : 7.128021726052507\n",
      "step : 400 // loss value : 2.2793037304560286\n",
      "step : 800 // loss value : 2.176593701250893\n",
      "step : 1200 // loss value : 1.9740141386532604\n",
      "step : 1600 // loss value : 1.6041187344962746\n",
      "step : 2000 // loss value : 1.2220381679849508\n",
      "step : 2400 // loss value : 0.9140123321940549\n",
      "step : 2800 // loss value : 0.6771377866381121\n",
      "step : 3200 // loss value : 0.5049296421041277\n",
      "step : 3600 // loss value : 0.3841535237291055\n",
      "step : 4000 // loss value : 0.29993723151282986\n",
      "step : 4400 // loss value : 0.24039597167294474\n",
      "step : 4800 // loss value : 0.1973324447891427\n",
      "step : 5200 // loss value : 0.1653929022283607\n",
      "step : 5600 // loss value : 0.14111723512090515\n",
      "step : 6000 // loss value : 0.12224686471071336\n",
      "step : 6400 // loss value : 0.10727958775720392\n",
      "step : 6800 // loss value : 0.09519412451583897\n",
      "step : 7200 // loss value : 0.08528045237937326\n",
      "step : 7600 // loss value : 0.07703420287114884\n",
      "step : 8000 // loss value : 0.07008980351705671\n",
      "step : 8400 // loss value : 0.06417731087440212\n",
      "step : 8800 // loss value : 0.05909397090737231\n",
      "step : 9200 // loss value : 0.05468510753360421\n",
      "step : 9600 // loss value : 0.050831034584094215\n",
      "step : 10000 // loss value : 0.04743793172290624\n"
     ]
    }
   ],
   "source": [
    "# AND 게이트 훈련\n",
    "xdata = np.array([ [0,0],[0,1],[1,0],[1,1] ])\n",
    "tdata = np.array([ 0,0,0,1 ])\n",
    "\n",
    "AND_obj = LogicGate(\"AND_GATE\", xdata, tdata)\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9da7509-44b6-405b-bd90-8222b5638a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.00010505]), 0)\n",
      "(array([0.01197144]), 0)\n",
      "(array([0.01096583]), 0)\n",
      "(array([0.97602878]), 1)\n"
     ]
    }
   ],
   "source": [
    "# AND Gate prediction\n",
    "print(AND_obj.name)\n",
    "\n",
    "test_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(AND_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a80add3-99ad-45de-9a71-043abdd67889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss_func : 3.2297937566632635\n",
      "step : 0 // loss value : 3.204508006122561\n",
      "step : 400 // loss value : 2.0164539919550633\n",
      "step : 800 // loss value : 1.8051001735569114\n",
      "step : 1200 // loss value : 1.5114561229402101\n",
      "step : 1600 // loss value : 1.161751606569039\n",
      "step : 2000 // loss value : 0.83743195712788\n",
      "step : 2400 // loss value : 0.5936396937264904\n",
      "step : 2800 // loss value : 0.4291557674147177\n",
      "step : 3200 // loss value : 0.3210852667531618\n",
      "step : 3600 // loss value : 0.2489480129566724\n",
      "step : 4000 // loss value : 0.19924852068156057\n",
      "step : 4400 // loss value : 0.16380207522582788\n",
      "step : 4800 // loss value : 0.1376859018217785\n",
      "step : 5200 // loss value : 0.11788065683381167\n",
      "step : 5600 // loss value : 0.10247988313613114\n",
      "step : 6000 // loss value : 0.09024197213816929\n",
      "step : 6400 // loss value : 0.08033384198374148\n",
      "step : 6800 // loss value : 0.07218091540795814\n",
      "step : 7200 // loss value : 0.06537688650036742\n",
      "step : 7600 // loss value : 0.05962791222121991\n",
      "step : 8000 // loss value : 0.054717154103516324\n",
      "step : 8400 // loss value : 0.05048167418707566\n",
      "step : 8800 // loss value : 0.046797025530072284\n",
      "step : 9200 // loss value : 0.04356675206716153\n",
      "step : 9600 // loss value : 0.04071509183262245\n",
      "step : 10000 // loss value : 0.03818181423741344\n"
     ]
    }
   ],
   "source": [
    "# OR 게이트 훈련\n",
    "xdata = np.array([ [0,0],[0,1],[1,0],[1,1] ])\n",
    "tdata = np.array([ 0,1,1,1 ])\n",
    "\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata)\n",
    "OR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f2a99c-7662-4830-81d6-5211d30bee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR_GATE \n",
      "\n",
      "(array([0.02288909]), 0)\n",
      "(array([0.99280267]), 1)\n",
      "(array([0.99241214]), 1)\n",
      "(array([0.99981306]), 1)\n"
     ]
    }
   ],
   "source": [
    "# OR Gate prediction\n",
    "print(OR_obj.name)\n",
    "\n",
    "test_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print( OR_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c42e13-a008-4f02-99df-ab0fb8b7cf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss_func : 3.118356211168441\n",
      "step : 0 // loss value : 3.092322518598521\n",
      "step : 400 // loss value : 2.178842253588977\n",
      "step : 800 // loss value : 1.9862363373024645\n",
      "step : 1200 // loss value : 1.661508701701921\n",
      "step : 1600 // loss value : 1.2960843918035785\n",
      "step : 2000 // loss value : 0.9687537007645846\n",
      "step : 2400 // loss value : 0.7092118857324756\n",
      "step : 2800 // loss value : 0.5224130328146117\n",
      "step : 3200 // loss value : 0.39408171392981584\n",
      "step : 3600 // loss value : 0.306226209710764\n",
      "step : 4000 // loss value : 0.24491713380592792\n",
      "step : 4400 // loss value : 0.20094372210837788\n",
      "step : 4800 // loss value : 0.16849133593998133\n",
      "step : 5200 // loss value : 0.14389322288527742\n",
      "step : 5600 // loss value : 0.12479666487337834\n",
      "step : 6000 // loss value : 0.10965529830828408\n",
      "step : 6400 // loss value : 0.09742635915671438\n",
      "step : 6800 // loss value : 0.08738891737164091\n",
      "step : 7200 // loss value : 0.07903278067232844\n",
      "step : 7600 // loss value : 0.07198907385815834\n",
      "step : 8000 // loss value : 0.06598584343138242\n",
      "step : 8400 // loss value : 0.06081901336507632\n",
      "step : 8800 // loss value : 0.05633296831281579\n",
      "step : 9200 // loss value : 0.052407307305399144\n",
      "step : 9600 // loss value : 0.04894763531689261\n",
      "step : 10000 // loss value : 0.04587904940725611\n"
     ]
    }
   ],
   "source": [
    "# NAND 게이트 훈련\n",
    "xdata = np.array([ [0,0],[0,1],[1,0],[1,1] ])\n",
    "tdata = np.array([ 1,1,1,0 ])\n",
    "\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata)\n",
    "NAND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead87efe-b0f5-44a1-996d-b14cb716db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND_GATE \n",
      "\n",
      "(array([0.99983395]), 1)\n",
      "(array([0.98883266]), 1)\n",
      "(array([0.98830948]), 1)\n",
      "(array([0.02246759]), 0)\n"
     ]
    }
   ],
   "source": [
    "# NAND Gate prediction\n",
    "print(NAND_obj.name)\n",
    "\n",
    "test_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(NAND_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf64385-d679-42bb-81de-9d620978ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss_func : 6.597356115897554\n",
      "step : 0 // loss value : 6.458579914700324\n",
      "step : 400 // loss value : 2.765212360477822\n",
      "step : 800 // loss value : 2.762574807482694\n",
      "step : 1200 // loss value : 2.759031843036044\n",
      "step : 1600 // loss value : 2.754196454857099\n",
      "step : 2000 // loss value : 2.7475191193122157\n",
      "step : 2400 // loss value : 2.738223916998657\n",
      "step : 2800 // loss value : 2.725224371073343\n",
      "step : 3200 // loss value : 2.7070152487812513\n",
      "step : 3600 // loss value : 2.6815514211035594\n",
      "step : 4000 // loss value : 2.6461926781045437\n",
      "step : 4400 // loss value : 2.597956951667438\n",
      "step : 4800 // loss value : 2.534453216031776\n",
      "step : 5200 // loss value : 2.4553992580387387\n",
      "step : 5600 // loss value : 2.363395708490598\n",
      "step : 6000 // loss value : 2.262584753516423\n",
      "step : 6400 // loss value : 2.156064700427507\n",
      "step : 6800 // loss value : 2.0442023713858095\n",
      "step : 7200 // loss value : 1.9249318187180484\n",
      "step : 7600 // loss value : 1.7958013883049138\n",
      "step : 8000 // loss value : 1.6563743167275886\n",
      "step : 8400 // loss value : 1.5093095244773491\n",
      "step : 8800 // loss value : 1.3598429530016722\n",
      "step : 9200 // loss value : 1.2140740489222233\n",
      "step : 9600 // loss value : 1.0769200397376377\n",
      "step : 10000 // loss value : 0.9510924586412899\n"
     ]
    }
   ],
   "source": [
    "# XOR 게이트 훈련\n",
    "xdata = np.array([ [0,0],[0,1],[1,0],[1,1] ])\n",
    "tdata = np.array([ 0,1,1,0 ])\n",
    "\n",
    "XOR_obj = LogicGate(\"XOR_GATE\", xdata, tdata)\n",
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2f9f2-70bd-4726-8caf-d70a484d963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR Gate prediction\n",
    "print(XOR_obj.name)\n",
    "\n",
    "test_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoidid_val, logical_val) = XOR_obj.predict(input_data)\n",
    "    print( input_data, ' = ', logical_val, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
